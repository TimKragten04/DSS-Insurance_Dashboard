{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving the data\n",
    "\n",
    "In order to estimate home-insurance premium for different regions in the country, a variety of datasets will be used. These datasets are retrieved from two sources, namely the police and the CBS (Central Bureau of Statistics). This document will contain all functionalities for retrieving the desired data and temporarily storing it, such that it can be cleaned, analyzed and displayed on the dashboard later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality setup\n",
    "\n",
    "This section contains global variables and helper functions that aid the retrieving and storing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required dependencies\n",
    "import requests\n",
    "import pandas as pd\n",
    "import cbsodata\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path where all the datasets will be stored\n",
    "data_path: str = r\"../data\"\n",
    "\n",
    "\n",
    "def dataframe_to_csv(df: pd.DataFrame, save_folder: Path, file_name: str) -> None:\n",
    "    \"\"\" Converts a DataFrame to a csv file and saves it at a specific location\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to be converted to CSV\n",
    "        save_folder (Path): The folder in which the file needs to be saved\n",
    "        file_name (str): The actual name of the file\n",
    "    \"\"\"\n",
    "    df.to_csv(f\"{save_folder}/{file_name}.csv\", \",\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic data from the police\n",
    "\n",
    "The dutch police department has provided API access to a database that contains information ranging from missing persons and police stations to patrol agents and general news articles. This data is updated in daily, which is why it is used in this project to satisfy the dynamic dataset requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_police_data(target_url: str, max_requests: int = 10, parameters: dict[str, str] = {}) -> pd.DataFrame:\n",
    "    \"\"\" Gets the data from the police API back in a dataframe. Since the API is limited to only returning 25 records,\n",
    "    the API gets queried for a specified numer of times. While making the API call, it is possible to add additional parameters\n",
    "\n",
    "    Args:\n",
    "        target_url (str): The url for the specific data that you want to retrieve from the police\n",
    "        max_requests (int, optional): Maximum number of requests made to the police API. Defaults to 10\n",
    "        parameters (dict[str, str], optional): Additional parameters that can be added to the API request. Defaults to {}.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the desired data\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame = pd.DataFrame()\n",
    "    request_index: int = 1\n",
    "\n",
    "    # Adding the parameters to the target url\n",
    "    if parameters != {}:\n",
    "        target_url = f\"{target_url}?\"\n",
    "\n",
    "        for parameter, value in parameters.items():\n",
    "            if value != None:\n",
    "                target_url = f\"{target_url}{parameter}={value}&\"\n",
    "\n",
    "    base_url: str = target_url\n",
    "\n",
    "    # Making the requests\n",
    "    while request_index <= max_requests:\n",
    "        print(f\"Starting request {str(request_index)}/{str(max_requests)}...\")\n",
    "        # Calculate the offset\n",
    "        offset: int = (request_index - 1) * 25\n",
    "        \n",
    "        if parameter != {}:\n",
    "            target_url = f\"{base_url}offset={offset}\"\n",
    "        else:\n",
    "            target_url = f\"{base_url}&offset={offset}\"\n",
    "\n",
    "        r = requests.get(target_url).json()\n",
    "        df = pd.concat([df, pd.DataFrame(r[\"opsporingsberichten\"])], ignore_index=True)\n",
    "\n",
    "        request_index = request_index + 1\n",
    "\n",
    "    print(\"Finished requests\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting request 1/3...\n",
      "Starting request 2/3...\n",
      "Starting request 3/3...\n",
      "Finished requests\n"
     ]
    }
   ],
   "source": [
    "police_url: str = \"https://api.politie.nl/v4/gezocht\"\n",
    "\n",
    "wanted_persons_parameters: dict[str, str] = {\n",
    "    \"uid\": None,\n",
    "    \"language\": \"nl\",\n",
    "    \"query\": None,\n",
    "    \"lat\": None,\n",
    "    \"lon\": None,\n",
    "    \"radius\": None,\n",
    "    \"maxnumberofitems\": \"25\"\n",
    "}\n",
    "\n",
    "police_datadata: pd.DataFrame = get_police_data(police_url, 3, wanted_persons_parameters)\n",
    "dataframe_to_csv(police_datadata, data_path, \"wanted_persons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data from CBS\n",
    "\n",
    "The Central Bureau for Statistics in the Netherlands provides all Dutch citizens with free datasets that can be analyzed. The datasets that are provided have all sorts of topics. In the report we provide a justification which dataset is used and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70072ned: Regional metrics of all of the netherlands. Big dataset with a lot of information. Based on municipality\n",
    "cbs_datasets: dict[str, str] = {\n",
    "    \"income_houshold\": \"85342NED\"\n",
    "}\n",
    "\n",
    "\n",
    "for dataset, identifier in cbs_datasets.items():\n",
    "    data = pd.DataFrame(cbsodata.get_data(identifier, dir=f\"../data/{dataset}\"))\n",
    "    data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income inequality\n",
    "\n",
    "The dataset \"Inkomen van huishoudens; huishoudenskenmerken, regio (indeling 2022)\" (85342NED) contains information about the average and median standardised income for private housholds\". The data that are retrieved from CBS are stored in several JSON files, one of them containing the actual income data, the others containing metadata on the dataset. In this section, the JSON files are cleaned such that redundant data are removed, and many codes are translated to readable format (e.g. PV20 will become Groningen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_income_dataset(dataset_path: Path, save_folder: Path, file_name: str) -> None:\n",
    "    \"\"\"\n",
    "    Clean the income dataset. First all redundant values are removed from the JSON. Next, all region codes are translated\n",
    "    to actual region names, income values are changed to the right format and extra information is added. The results are\n",
    "    stored in a csv file, which can put in a database.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (Path): The path to the folder that contains all JSONs.\n",
    "        save_folder (Path): Folder where the cleaned csv needs to be saved.\n",
    "        file_name (str): Name of the resulting file.\n",
    "    \"\"\"\n",
    "    print(\"Started: Cleaning income dataset\")\n",
    "\n",
    "    # Create some variables for the names of JSONs that will be used\n",
    "    dataset_income_name: str = \"TypedDataSet.json\"\n",
    "    dataset_regions_name: str = \"RegioS.json\"\n",
    "\n",
    "    # First store the necessary datasets in variables\n",
    "    with open(f\"{dataset_path}/{dataset_income_name}\", \"r\") as f:\n",
    "        income_dataset = json.load(f)\n",
    "\n",
    "    with open(f\"{dataset_path}/{dataset_regions_name}\", \"r\") as f:\n",
    "        regions_dataset = json.load(f)\n",
    "    \n",
    "    # Remove all redundant values from the dataset\n",
    "    income_dataset = remove_redundant_values_income_dataset(income_dataset)\n",
    "    income_dataset = transform_values_income_dataset(income_dataset, regions_dataset)\n",
    "\n",
    "    income_df: pd.DataFrame = pd.DataFrame(income_dataset)\n",
    "\n",
    "    dataframe_to_csv(income_df, save_folder, file_name)\n",
    "\n",
    "    print(\"Ended: Cleaning income dataset\")\n",
    "    \n",
    "\n",
    "def remove_redundant_values_income_dataset(dataset: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    In the income dataset there are some values that need to be removed. These are the values that don't contain the right\n",
    "    region level or not the right houshold features.\n",
    "\n",
    "    Args:\n",
    "        dataset (dict[str, Any]): Income dataset to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: Cleaned income dataset.\n",
    "    \"\"\"\n",
    "    print(\"Started: Removing redundant values income dataset\")\n",
    "\n",
    "    # remove all data that does not have to do with private housholds\n",
    "    dataset: dict[str, Any] = [item for item in dataset if item[\"KenmerkenVanHuishoudens\"] == \"1050010\"]\n",
    "    dataset: dict[str, Any] = [item for item in dataset if item[\"Populatie\"] == \"1050010\"]\n",
    "\n",
    "    # keep all data that has the correct region type (national level, province level or municipality level)\n",
    "    dataset: dict[str, Any] = [item for item in dataset if  item[\"RegioS\"].startswith(\"NL\") or\n",
    "                                                            item[\"RegioS\"].startswith(\"PV\") or\n",
    "                                                            item[\"RegioS\"].startswith(\"GM\")]\n",
    "    \n",
    "    # Remove all redundant data\n",
    "    for item in dataset:\n",
    "        item.pop(\"ID\", None)\n",
    "        item.pop(\"KenmerkenVanHuishoudens\", None)\n",
    "        item.pop(\"ParticuliereHuishoudensRelatief_2\", None)\n",
    "        item.pop(\"GemiddeldBesteedbaarInkomen_5\", None)\n",
    "        item.pop(\"MediaanBesteedbaarInkomen_6\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen1e10Groep_7\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen2e10Groep_8\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen3e10Groep_9\", None)   \n",
    "        item.pop(\"GestandaardiseerdInkomen4e10Groep_10\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen5e10Groep_11\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen6e10Groep_12\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen7e10Groep_13\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen8e10Groep_14\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen9e10Groep_15\", None)\n",
    "        item.pop(\"GestandaardiseerdInkomen10e10Groep_16\", None)\n",
    "\n",
    "    print(\"Ended: Removing redundant values income dataset\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def transform_values_income_dataset(income_dataset: dict[str, Any], region_dataset: dict[str, Any]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Transforms all data in the correct format. This means transforming the population code, transforming the region code,\n",
    "    updating the houshold amount and updating the income values.\n",
    "\n",
    "    Args:\n",
    "        income_dataset (dict[str, Any]): The income dataset, where values still need to be transformed.\n",
    "        region_dataset (dict[str, Any]): The regions dataset, to translate region codes to actual region names.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, Any]: The income dataset with transformed values.\n",
    "    \"\"\"\n",
    "    print(\"Started: Transforming values income dataset\")\n",
    "\n",
    "    # Create a dictionary from the regions dataset, where the key is the region-key and the values are the corresponsing values\n",
    "    converted_region_dataset: dict[str, Any] = {}\n",
    "\n",
    "    for item in region_dataset:\n",
    "        key = item.get(\"Key\")\n",
    "        if key is not None:\n",
    "            item.pop(\"Key\")\n",
    "            converted_region_dataset[key] = item\n",
    "\n",
    "    # Transforms data in the right format and deletes redundant data\n",
    "    for item in income_dataset:\n",
    "        \n",
    "        # Check the region for each item in the dataset and set the region type and name\n",
    "        match item[\"RegioS\"][0:2]:\n",
    "            case \"NL\":\n",
    "                region_type: str = \"Country\"\n",
    "                region_name: str = converted_region_dataset[item[\"RegioS\"]][\"Title\"]\n",
    "            case \"PV\":\n",
    "                region_type: str = \"Province\"\n",
    "                region_name: str = converted_region_dataset[item[\"RegioS\"]][\"Title\"][:-5]\n",
    "            case \"GM\":\n",
    "                region_type: str = \"Municipality\"\n",
    "                region_name: str = converted_region_dataset[item[\"RegioS\"]][\"Title\"]\n",
    "\n",
    "        item[\"dataset\"] = \"income_inequality\"\n",
    "        item[\"time_period\"] = item[\"Perioden\"][0:4]\n",
    "        item[\"region_name\"] = region_name\n",
    "        item[\"region_type\"] = region_type\n",
    "        item[\"region_code\"] = item[\"RegioS\"].strip()\n",
    "        item[\"population\"] = \"Private housholds\"\n",
    "        item[\"private_houshold_amount\"] = round(item[\"ParticuliereHuishoudens_1\"] * 1000, 1)\n",
    "        item[\"average_standardized_income\"] = round(item[\"GemiddeldGestandaardiseerdInkomen_3\"] * 1000, 1)\n",
    "        item[\"median_standardized_income\"] = round(item[\"MediaanGestandaardiseerdInkomen_4\"] * 1000, 1)\n",
    "        item[\"inequality_income\"] = round(item[\"average_standardized_income\"] - item[\"median_standardized_income\"], 1)\n",
    "\n",
    "        # Delete remaining redundant data\n",
    "        item.pop(\"Populatie\", None)\n",
    "        item.pop(\"RegioS\", None)\n",
    "        item.pop(\"Perioden\", None)\n",
    "        item.pop(\"ParticuliereHuishoudens_1\", None)\n",
    "        item.pop(\"GemiddeldGestandaardiseerdInkomen_3\", None)\n",
    "        item.pop(\"MediaanGestandaardiseerdInkomen_4\", None)\n",
    "\n",
    "    print(\"Ended: Transforming values income dataset\")\n",
    "\n",
    "    return income_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started: Cleaning income dataset\n",
      "Ended: Cleaning income dataset\n"
     ]
    }
   ],
   "source": [
    "clean_income_dataset(r\"../data/income_houshold\", \".\", \"income_inequality_cleaned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
